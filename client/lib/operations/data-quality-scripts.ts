// Comprehensive Data Quality (DQ) Scripts for Banking Domains
// Includes validation rules, anomaly detection, and monitoring

export const DataQualityScripts = {
  bronze: {
    name: "Bronze Layer Data Quality",
    description: "Validation rules for raw ingested data",
    scripts: {
      completenessCheck: {
        name: "Completeness Check",
        description: "Validate required fields are populated",
        sql: `-- Bronze Layer: Completeness Check
-- Owner: Data Quality | Frequency: Daily Post-Load
-- Purpose: Identify missing or NULL values in critical columns

DECLARE @CheckDate DATETIME2 = GETDATE();
DECLARE @LoadDate DATE = CAST(@CheckDate AS DATE);

INSERT INTO CONTROL.DATA_QUALITY_RESULTS (CHECK_NAME, TABLE_NAME, CHECK_TYPE, PASSED_COUNT, FAILED_COUNT, TOTAL_COUNT, PASS_RATE, EXECUTION_TIME, STATUS)
SELECT 
  'COMPLETENESS_CHECK' AS CHECK_NAME,
  'BRONZE.CUSTOMER' AS TABLE_NAME,
  'REQUIRED_FIELDS' AS CHECK_TYPE,
  SUM(CASE WHEN CUSTOMER_ID IS NOT NULL AND CUSTOMER_TYPE IS NOT NULL AND EMAIL IS NOT NULL THEN 1 ELSE 0 END) AS PASSED_COUNT,
  SUM(CASE WHEN CUSTOMER_ID IS NULL OR CUSTOMER_TYPE IS NULL OR EMAIL IS NULL THEN 1 ELSE 0 END) AS FAILED_COUNT,
  COUNT(*) AS TOTAL_COUNT,
  CAST(SUM(CASE WHEN CUSTOMER_ID IS NOT NULL AND CUSTOMER_TYPE IS NOT NULL AND EMAIL IS NOT NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)) AS PASS_RATE,
  @CheckDate AS EXECUTION_TIME,
  CASE WHEN CAST(SUM(CASE WHEN CUSTOMER_ID IS NOT NULL AND CUSTOMER_TYPE IS NOT NULL AND EMAIL IS NOT NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)) >= 95 THEN 'PASS' ELSE 'FAIL' END AS STATUS
FROM BRONZE.CUSTOMER
WHERE CAST(CREATED_DATE AS DATE) = @LoadDate
UNION ALL
SELECT 'COMPLETENESS_CHECK', 'BRONZE.ACCOUNT', 'REQUIRED_FIELDS',
  SUM(CASE WHEN ACCOUNT_NUMBER IS NOT NULL AND ACCOUNT_TYPE IS NOT NULL AND ACCOUNT_STATUS IS NOT NULL THEN 1 ELSE 0 END),
  SUM(CASE WHEN ACCOUNT_NUMBER IS NULL OR ACCOUNT_TYPE IS NULL OR ACCOUNT_STATUS IS NULL THEN 1 ELSE 0 END),
  COUNT(*),
  CAST(SUM(CASE WHEN ACCOUNT_NUMBER IS NOT NULL AND ACCOUNT_TYPE IS NOT NULL AND ACCOUNT_STATUS IS NOT NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)),
  @CheckDate,
  CASE WHEN CAST(SUM(CASE WHEN ACCOUNT_NUMBER IS NOT NULL AND ACCOUNT_TYPE IS NOT NULL AND ACCOUNT_STATUS IS NOT NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)) >= 95 THEN 'PASS' ELSE 'FAIL' END
FROM BRONZE.ACCOUNT
WHERE CAST(CREATED_DATE AS DATE) = @LoadDate;`,
      },
      uniquenessCheck: {
        name: "Uniqueness/Duplicates Check",
        description: "Detect duplicate primary keys and business keys",
        sql: `-- Bronze Layer: Uniqueness Check
-- Purpose: Identify duplicate records within Bronze layer tables

DECLARE @CheckDate DATETIME2 = GETDATE();

INSERT INTO CONTROL.DATA_QUALITY_RESULTS (CHECK_NAME, TABLE_NAME, CHECK_TYPE, PASSED_COUNT, FAILED_COUNT, TOTAL_COUNT, PASS_RATE, EXECUTION_TIME, STATUS)
SELECT 
  'UNIQUENESS_CHECK' AS CHECK_NAME,
  'BRONZE.CUSTOMER' AS TABLE_NAME,
  'DUPLICATE_PRIMARY_KEY' AS CHECK_TYPE,
  COUNT(DISTINCT CUSTOMER_ID) AS PASSED_COUNT,
  COUNT(*) - COUNT(DISTINCT CUSTOMER_ID) AS FAILED_COUNT,
  COUNT(*) AS TOTAL_COUNT,
  CAST(COUNT(DISTINCT CUSTOMER_ID) * 100.0 / COUNT(*) AS DECIMAL(5,2)) AS PASS_RATE,
  @CheckDate,
  CASE WHEN COUNT(*) = COUNT(DISTINCT CUSTOMER_ID) THEN 'PASS' ELSE 'FAIL' END
FROM BRONZE.CUSTOMER
UNION ALL
SELECT 'UNIQUENESS_CHECK', 'BRONZE.ACCOUNT', 'DUPLICATE_PRIMARY_KEY',
  COUNT(DISTINCT ACCOUNT_NUMBER),
  COUNT(*) - COUNT(DISTINCT ACCOUNT_NUMBER),
  COUNT(*),
  CAST(COUNT(DISTINCT ACCOUNT_NUMBER) * 100.0 / COUNT(*) AS DECIMAL(5,2)),
  @CheckDate,
  CASE WHEN COUNT(*) = COUNT(DISTINCT ACCOUNT_NUMBER) THEN 'PASS' ELSE 'FAIL' END
FROM BRONZE.ACCOUNT;`,
      },
      validationRules: {
        name: "Data Type & Format Validation",
        description: "Validate data types, formats, and value ranges",
        sql: `-- Bronze Layer: Data Validation Rules
-- Purpose: Check data types, formats, and valid value ranges

DECLARE @CheckDate DATETIME2 = GETDATE();

INSERT INTO CONTROL.DATA_QUALITY_RESULTS (CHECK_NAME, TABLE_NAME, CHECK_TYPE, PASSED_COUNT, FAILED_COUNT, TOTAL_COUNT, PASS_RATE, EXECUTION_TIME, STATUS)
SELECT 
  'VALIDATION_RULES' AS CHECK_NAME,
  'BRONZE.CUSTOMER' AS TABLE_NAME,
  'VALID_EMAIL_FORMAT' AS CHECK_TYPE,
  SUM(CASE WHEN EMAIL LIKE '%@%.%' OR EMAIL = '' THEN 1 ELSE 0 END) AS PASSED_COUNT,
  SUM(CASE WHEN EMAIL NOT LIKE '%@%.%' AND EMAIL != '' THEN 1 ELSE 0 END) AS FAILED_COUNT,
  COUNT(*) AS TOTAL_COUNT,
  CAST(SUM(CASE WHEN EMAIL LIKE '%@%.%' OR EMAIL = '' THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)) AS PASS_RATE,
  @CheckDate,
  CASE WHEN SUM(CASE WHEN EMAIL NOT LIKE '%@%.%' AND EMAIL != '' THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM BRONZE.CUSTOMER
UNION ALL
SELECT 'VALIDATION_RULES', 'BRONZE.CUSTOMER', 'VALID_CUSTOMER_STATUS',
  SUM(CASE WHEN CUSTOMER_STATUS IN ('ACTIVE', 'INACTIVE', 'CLOSED') THEN 1 ELSE 0 END),
  SUM(CASE WHEN CUSTOMER_STATUS NOT IN ('ACTIVE', 'INACTIVE', 'CLOSED') THEN 1 ELSE 0 END),
  COUNT(*),
  CAST(SUM(CASE WHEN CUSTOMER_STATUS IN ('ACTIVE', 'INACTIVE', 'CLOSED') THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)),
  @CheckDate,
  CASE WHEN SUM(CASE WHEN CUSTOMER_STATUS NOT IN ('ACTIVE', 'INACTIVE', 'CLOSED') THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM BRONZE.CUSTOMER
UNION ALL
SELECT 'VALIDATION_RULES', 'BRONZE.ACCOUNT', 'POSITIVE_BALANCE',
  SUM(CASE WHEN ACCOUNT_BALANCE >= 0 THEN 1 ELSE 0 END),
  SUM(CASE WHEN ACCOUNT_BALANCE < 0 THEN 1 ELSE 0 END),
  COUNT(*),
  CAST(SUM(CASE WHEN ACCOUNT_BALANCE >= 0 THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)),
  @CheckDate,
  CASE WHEN SUM(CASE WHEN ACCOUNT_BALANCE < 0 THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM BRONZE.ACCOUNT;`,
      },
      freshness: {
        name: "Data Freshness & Timeliness",
        description: "Validate data is loaded within SLA windows",
        sql: `-- Bronze Layer: Data Freshness Check
-- Purpose: Ensure data loads are completed within SLA timeframes

DECLARE @CheckDate DATETIME2 = GETDATE();
DECLARE @MaxAllowedHours INT = 24;

INSERT INTO CONTROL.DATA_QUALITY_RESULTS (CHECK_NAME, TABLE_NAME, CHECK_TYPE, PASSED_COUNT, FAILED_COUNT, TOTAL_COUNT, PASS_RATE, EXECUTION_TIME, STATUS)
SELECT 
  'FRESHNESS_CHECK' AS CHECK_NAME,
  TABLE_NAME,
  'DATA_LOAD_SLA' AS CHECK_TYPE,
  COUNT(*) AS PASSED_COUNT,
  0 AS FAILED_COUNT,
  COUNT(*) AS TOTAL_COUNT,
  100.0 AS PASS_RATE,
  @CheckDate,
  CASE WHEN DATEDIFF(HOUR, MAX(LAST_MODIFIED_DATE), @CheckDate) <= @MaxAllowedHours THEN 'PASS' ELSE 'FAIL' END
FROM (
  SELECT TABLE_NAME, MAX(LAST_MODIFIED_DATE) AS LAST_MODIFIED_DATE FROM BRONZE.CUSTOMER GROUP BY TABLE_NAME
  UNION ALL
  SELECT TABLE_NAME, MAX(LAST_MODIFIED_DATE) FROM BRONZE.ACCOUNT GROUP BY TABLE_NAME
) AS LoadStatus
GROUP BY TABLE_NAME;`,
      },
    },
  },
  silver: {
    name: "Silver Layer Data Quality",
    description: "Validation rules for cleansed and conformed data",
    scripts: {
      referentialIntegrity: {
        name: "Referential Integrity Check",
        description: "Validate foreign key relationships",
        sql: `-- Silver Layer: Referential Integrity Check
-- Purpose: Ensure foreign key constraints and cross-table relationships are valid

DECLARE @CheckDate DATETIME2 = GETDATE();

INSERT INTO CONTROL.DATA_QUALITY_RESULTS (CHECK_NAME, TABLE_NAME, CHECK_TYPE, PASSED_COUNT, FAILED_COUNT, TOTAL_COUNT, PASS_RATE, EXECUTION_TIME, STATUS)
SELECT 
  'REFERENTIAL_INTEGRITY' AS CHECK_NAME,
  'SILVER.FCT_ACCOUNT_TRANSACTIONS' AS TABLE_NAME,
  'VALID_CUSTOMER_KEY' AS CHECK_TYPE,
  COUNT(*) AS PASSED_COUNT,
  SUM(CASE WHEN CUSTOMER_KEY NOT IN (SELECT CUSTOMER_KEY FROM SILVER.DIM_CUSTOMER_GOLDEN WHERE IS_CURRENT = 1) THEN 1 ELSE 0 END) AS FAILED_COUNT,
  COUNT(*) AS TOTAL_COUNT,
  CAST((COUNT(*) - SUM(CASE WHEN CUSTOMER_KEY NOT IN (SELECT CUSTOMER_KEY FROM SILVER.DIM_CUSTOMER_GOLDEN WHERE IS_CURRENT = 1) THEN 1 ELSE 0 END)) * 100.0 / COUNT(*) AS DECIMAL(5,2)) AS PASS_RATE,
  @CheckDate,
  CASE WHEN SUM(CASE WHEN CUSTOMER_KEY NOT IN (SELECT CUSTOMER_KEY FROM SILVER.DIM_CUSTOMER_GOLDEN WHERE IS_CURRENT = 1) THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM SILVER.FCT_ACCOUNT_TRANSACTIONS
UNION ALL
SELECT 'REFERENTIAL_INTEGRITY', 'SILVER.FCT_DEPOSIT_DAILY_BALANCE', 'VALID_ACCOUNT_KEY',
  COUNT(*),
  SUM(CASE WHEN ACCOUNT_KEY NOT IN (SELECT ACCOUNT_KEY FROM SILVER.DIM_ACCOUNT WHERE IS_CURRENT = 1) THEN 1 ELSE 0 END),
  COUNT(*),
  CAST((COUNT(*) - SUM(CASE WHEN ACCOUNT_KEY NOT IN (SELECT ACCOUNT_KEY FROM SILVER.DIM_ACCOUNT WHERE IS_CURRENT = 1) THEN 1 ELSE 0 END)) * 100.0 / COUNT(*) AS DECIMAL(5,2)),
  @CheckDate,
  CASE WHEN SUM(CASE WHEN ACCOUNT_KEY NOT IN (SELECT ACCOUNT_KEY FROM SILVER.DIM_ACCOUNT WHERE IS_CURRENT = 1) THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM SILVER.FCT_DEPOSIT_DAILY_BALANCE;`,
      },
      scdValidation: {
        name: "SCD Type 2 Validation",
        description: "Validate Slowly Changing Dimension tracking",
        sql: `-- Silver Layer: SCD Type 2 Validation
-- Purpose: Ensure dimension tables maintain proper effective date tracking and current flags

DECLARE @CheckDate DATETIME2 = GETDATE();

INSERT INTO CONTROL.DATA_QUALITY_RESULTS (CHECK_NAME, TABLE_NAME, CHECK_TYPE, PASSED_COUNT, FAILED_COUNT, TOTAL_COUNT, PASS_RATE, EXECUTION_TIME, STATUS)
SELECT 
  'SCD2_VALIDATION' AS CHECK_NAME,
  'SILVER.DIM_CUSTOMER_GOLDEN' AS TABLE_NAME,
  'EFFECTIVE_DATE_LOGIC' AS CHECK_TYPE,
  COUNT(*) AS PASSED_COUNT,
  SUM(CASE WHEN (IS_CURRENT = 1 AND EFFECTIVE_END_DATE IS NOT NULL) OR (IS_CURRENT = 0 AND EFFECTIVE_END_DATE IS NULL) THEN 1 ELSE 0 END) AS FAILED_COUNT,
  COUNT(*) AS TOTAL_COUNT,
  CAST((COUNT(*) - SUM(CASE WHEN (IS_CURRENT = 1 AND EFFECTIVE_END_DATE IS NOT NULL) OR (IS_CURRENT = 0 AND EFFECTIVE_END_DATE IS NULL) THEN 1 ELSE 0 END)) * 100.0 / COUNT(*) AS DECIMAL(5,2)) AS PASS_RATE,
  @CheckDate,
  CASE WHEN SUM(CASE WHEN (IS_CURRENT = 1 AND EFFECTIVE_END_DATE IS NOT NULL) OR (IS_CURRENT = 0 AND EFFECTIVE_END_DATE IS NULL) THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM SILVER.DIM_CUSTOMER_GOLDEN
UNION ALL
SELECT 'SCD2_VALIDATION', 'SILVER.DIM_CUSTOMER_GOLDEN', 'NO_OVERLAPPING_DATES',
  COUNT(*),
  SUM(CASE WHEN (LAG(EFFECTIVE_END_DATE) OVER (PARTITION BY CUSTOMER_ID ORDER BY EFFECTIVE_START_DATE) >= EFFECTIVE_START_DATE AND LAG(EFFECTIVE_END_DATE) OVER (PARTITION BY CUSTOMER_ID ORDER BY EFFECTIVE_START_DATE) IS NOT NULL) THEN 1 ELSE 0 END),
  COUNT(*),
  CAST((COUNT(*) - SUM(CASE WHEN (LAG(EFFECTIVE_END_DATE) OVER (PARTITION BY CUSTOMER_ID ORDER BY EFFECTIVE_START_DATE) >= EFFECTIVE_START_DATE AND LAG(EFFECTIVE_END_DATE) OVER (PARTITION BY CUSTOMER_ID ORDER BY EFFECTIVE_START_DATE) IS NOT NULL) THEN 1 ELSE 0 END)) * 100.0 / COUNT(*) AS DECIMAL(5,2)),
  @CheckDate,
  CASE WHEN SUM(CASE WHEN (LAG(EFFECTIVE_END_DATE) OVER (PARTITION BY CUSTOMER_ID ORDER BY EFFECTIVE_START_DATE) >= EFFECTIVE_START_DATE AND LAG(EFFECTIVE_END_DATE) OVER (PARTITION BY CUSTOMER_ID ORDER BY EFFECTIVE_START_DATE) IS NOT NULL) THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM SILVER.DIM_CUSTOMER_GOLDEN;`,
      },
      businessRules: {
        name: "Business Rules Validation",
        description: "Validate domain-specific business logic",
        sql: `-- Silver Layer: Business Rules Validation
-- Purpose: Enforce business logic rules specific to banking domain

DECLARE @CheckDate DATETIME2 = GETDATE();

INSERT INTO CONTROL.DATA_QUALITY_RESULTS (CHECK_NAME, TABLE_NAME, CHECK_TYPE, PASSED_COUNT, FAILED_COUNT, TOTAL_COUNT, PASS_RATE, EXECUTION_TIME, STATUS)
SELECT 
  'BUSINESS_RULES' AS CHECK_NAME,
  'SILVER.DIM_CUSTOMER_GOLDEN' AS TABLE_NAME,
  'VALID_SEGMENT_VALUES' AS CHECK_TYPE,
  SUM(CASE WHEN CUSTOMER_SEGMENT IN ('PREMIUM', 'STANDARD', 'BASIC', 'INACTIVE') THEN 1 ELSE 0 END) AS PASSED_COUNT,
  SUM(CASE WHEN CUSTOMER_SEGMENT NOT IN ('PREMIUM', 'STANDARD', 'BASIC', 'INACTIVE') THEN 1 ELSE 0 END) AS FAILED_COUNT,
  COUNT(*) AS TOTAL_COUNT,
  CAST(SUM(CASE WHEN CUSTOMER_SEGMENT IN ('PREMIUM', 'STANDARD', 'BASIC', 'INACTIVE') THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)) AS PASS_RATE,
  @CheckDate,
  CASE WHEN SUM(CASE WHEN CUSTOMER_SEGMENT NOT IN ('PREMIUM', 'STANDARD', 'BASIC', 'INACTIVE') THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM SILVER.DIM_CUSTOMER_GOLDEN
WHERE IS_CURRENT = 1
UNION ALL
SELECT 'BUSINESS_RULES', 'SILVER.DIM_ACCOUNT', 'VALID_ACCOUNT_STATUS',
  SUM(CASE WHEN ACCOUNT_STATUS IN ('ACTIVE', 'DORMANT', 'CLOSED', 'RESTRICTED') THEN 1 ELSE 0 END),
  SUM(CASE WHEN ACCOUNT_STATUS NOT IN ('ACTIVE', 'DORMANT', 'CLOSED', 'RESTRICTED') THEN 1 ELSE 0 END),
  COUNT(*),
  CAST(SUM(CASE WHEN ACCOUNT_STATUS IN ('ACTIVE', 'DORMANT', 'CLOSED', 'RESTRICTED') THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)),
  @CheckDate,
  CASE WHEN SUM(CASE WHEN ACCOUNT_STATUS NOT IN ('ACTIVE', 'DORMANT', 'CLOSED', 'RESTRICTED') THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM SILVER.DIM_ACCOUNT
WHERE IS_CURRENT = 1;`,
      },
    },
  },
  gold: {
    name: "Gold Layer Data Quality",
    description: "Validation rules for analytics-ready data",
    scripts: {
      aggregationValidation: {
        name: "Aggregation Accuracy Check",
        description: "Validate pre-calculated aggregations match source data",
        sql: `-- Gold Layer: Aggregation Validation
-- Purpose: Reconcile gold layer aggregations with silver source layer

DECLARE @CheckDate DATETIME2 = GETDATE();

INSERT INTO CONTROL.DATA_QUALITY_RESULTS (CHECK_NAME, TABLE_NAME, CHECK_TYPE, PASSED_COUNT, FAILED_COUNT, TOTAL_COUNT, PASS_RATE, EXECUTION_TIME, STATUS)
SELECT 
  'AGGREGATION_VALIDATION' AS CHECK_NAME,
  'ANALYTICS.CUSTOMER_DEPOSIT_AGGR' AS TABLE_NAME,
  'DEPOSIT_BALANCE_ACCURACY' AS CHECK_TYPE,
  SUM(CASE WHEN ABS(gold_balance - silver_balance) < 0.01 THEN 1 ELSE 0 END) AS PASSED_COUNT,
  SUM(CASE WHEN ABS(gold_balance - silver_balance) >= 0.01 THEN 1 ELSE 0 END) AS FAILED_COUNT,
  COUNT(*) AS TOTAL_COUNT,
  CAST(SUM(CASE WHEN ABS(gold_balance - silver_balance) < 0.01 THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)) AS PASS_RATE,
  @CheckDate,
  CASE WHEN SUM(CASE WHEN ABS(gold_balance - silver_balance) >= 0.01 THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM (
  SELECT 
    g.CUSTOMER_KEY,
    g.TOTAL_CUSTOMER_DEPOSITS AS gold_balance,
    SUM(s.ACCOUNT_BALANCE) AS silver_balance
  FROM ANALYTICS.CUSTOMER_DEPOSIT_AGGR g
  LEFT JOIN SILVER.DIM_ACCOUNT s ON g.CUSTOMER_KEY = s.CUSTOMER_KEY
  WHERE s.IS_CURRENT = 1
  GROUP BY g.CUSTOMER_KEY, g.TOTAL_CUSTOMER_DEPOSITS
) AS reconciliation;`,
      },
      metricValidation: {
        name: "Metric Calculation Validation",
        description: "Validate calculated metrics and KPIs",
        sql: `-- Gold Layer: Metric Validation
-- Purpose: Verify calculated metrics are within expected ranges

DECLARE @CheckDate DATETIME2 = GETDATE();

INSERT INTO CONTROL.DATA_QUALITY_RESULTS (CHECK_NAME, TABLE_NAME, CHECK_TYPE, PASSED_COUNT, FAILED_COUNT, TOTAL_COUNT, PASS_RATE, EXECUTION_TIME, STATUS)
SELECT 
  'METRIC_VALIDATION' AS CHECK_NAME,
  'ANALYTICS.FCT_DEPOSIT_DAILY_BALANCE' AS TABLE_NAME,
  'VALID_INTEREST_ACCRUAL' AS CHECK_TYPE,
  SUM(CASE WHEN INTEREST_ACCRUAL >= 0 AND INTEREST_ACCRUAL <= ACCOUNT_BALANCE * 0.20 THEN 1 ELSE 0 END) AS PASSED_COUNT,
  SUM(CASE WHEN INTEREST_ACCRUAL < 0 OR INTEREST_ACCRUAL > ACCOUNT_BALANCE * 0.20 THEN 1 ELSE 0 END) AS FAILED_COUNT,
  COUNT(*) AS TOTAL_COUNT,
  CAST(SUM(CASE WHEN INTEREST_ACCRUAL >= 0 AND INTEREST_ACCRUAL <= ACCOUNT_BALANCE * 0.20 THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)) AS PASS_RATE,
  @CheckDate,
  CASE WHEN SUM(CASE WHEN INTEREST_ACCRUAL < 0 OR INTEREST_ACCRUAL > ACCOUNT_BALANCE * 0.20 THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM ANALYTICS.FCT_DEPOSIT_DAILY_BALANCE
WHERE BALANCE_DATE = CAST(@CheckDate AS DATE);`,
      },
      outlierDetection: {
        name: "Outlier & Anomaly Detection",
        description: "Identify statistical anomalies and outliers",
        sql: `-- Gold Layer: Outlier Detection
-- Purpose: Identify unusual patterns using statistical methods

DECLARE @CheckDate DATETIME2 = GETDATE();
DECLARE @StdDevThreshold FLOAT = 3.0;

INSERT INTO CONTROL.DATA_QUALITY_RESULTS (CHECK_NAME, TABLE_NAME, CHECK_TYPE, PASSED_COUNT, FAILED_COUNT, TOTAL_COUNT, PASS_RATE, EXECUTION_TIME, STATUS)
SELECT 
  'OUTLIER_DETECTION' AS CHECK_NAME,
  'ANALYTICS.CUSTOMER_DEPOSIT_AGGR' AS TABLE_NAME,
  'DEPOSIT_BALANCE_OUTLIERS' AS CHECK_TYPE,
  SUM(CASE WHEN ABS((TOTAL_CUSTOMER_DEPOSITS - avg_deposit) / NULLIF(std_dev_deposit, 0)) <= @StdDevThreshold THEN 1 ELSE 0 END) AS PASSED_COUNT,
  SUM(CASE WHEN ABS((TOTAL_CUSTOMER_DEPOSITS - avg_deposit) / NULLIF(std_dev_deposit, 0)) > @StdDevThreshold THEN 1 ELSE 0 END) AS FAILED_COUNT,
  COUNT(*) AS TOTAL_COUNT,
  CAST(SUM(CASE WHEN ABS((TOTAL_CUSTOMER_DEPOSITS - avg_deposit) / NULLIF(std_dev_deposit, 0)) <= @StdDevThreshold THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)) AS PASS_RATE,
  @CheckDate,
  CASE WHEN SUM(CASE WHEN ABS((TOTAL_CUSTOMER_DEPOSITS - avg_deposit) / NULLIF(std_dev_deposit, 0)) > @StdDevThreshold THEN 1 ELSE 0 END) = 0 THEN 'PASS' ELSE 'FAIL' END
FROM (
  SELECT 
    *,
    AVG(TOTAL_CUSTOMER_DEPOSITS) OVER () AS avg_deposit,
    STDEV(TOTAL_CUSTOMER_DEPOSITS) OVER () AS std_dev_deposit
  FROM ANALYTICS.CUSTOMER_DEPOSIT_AGGR
) AS stats;`,
      },
    },
  },
  monitoring: {
    name: "Data Quality Monitoring & Alerting",
    description: "Real-time monitoring and alerting framework",
    scripts: {
      qualityDashboard: {
        name: "Data Quality Dashboard Query",
        description: "Overall data quality metrics and trends",
        sql: `-- Data Quality Dashboard: Executive Summary
-- Owner: Data Quality Team | Frequency: Real-time
-- Purpose: Provide overall data quality health across all layers

DECLARE @Last7Days DATETIME2 = DATEADD(DAY, -7, GETDATE());
DECLARE @Today DATE = CAST(GETDATE() AS DATE);

SELECT 
  dq.CHECK_NAME,
  dq.TABLE_NAME,
  dq.CHECK_TYPE,
  dq.TOTAL_COUNT,
  dq.PASSED_COUNT,
  dq.FAILED_COUNT,
  dq.PASS_RATE,
  dq.STATUS,
  CASE 
    WHEN dq.PASS_RATE >= 99 THEN 'EXCELLENT'
    WHEN dq.PASS_RATE >= 95 THEN 'GOOD'
    WHEN dq.PASS_RATE >= 90 THEN 'WARNING'
    ELSE 'CRITICAL'
  END AS HEALTH_STATUS,
  DATEDIFF(HOUR, dq.EXECUTION_TIME, GETDATE()) AS HOURS_AGO,
  LAG(dq.PASS_RATE) OVER (PARTITION BY dq.CHECK_NAME, dq.TABLE_NAME ORDER BY dq.EXECUTION_TIME) AS PREV_PASS_RATE,
  CAST((dq.PASS_RATE - LAG(dq.PASS_RATE) OVER (PARTITION BY dq.CHECK_NAME, dq.TABLE_NAME ORDER BY dq.EXECUTION_TIME)) AS DECIMAL(5,2)) AS PASS_RATE_TREND
FROM CONTROL.DATA_QUALITY_RESULTS dq
WHERE dq.EXECUTION_TIME >= @Last7Days
ORDER BY dq.EXECUTION_TIME DESC, dq.PASS_RATE ASC;`,
      },
      criticalFailureAlert: {
        name: "Critical Quality Failure Alert",
        description: "Identify and escalate critical data quality issues",
        sql: `-- Critical Data Quality Failure Alert
-- Purpose: Alert on data quality failures below SLA thresholds

DECLARE @CriticalThreshold DECIMAL(5,2) = 90.0;
DECLARE @WarningThreshold DECIMAL(5,2) = 95.0;

SELECT 
  CASE 
    WHEN PASS_RATE < @CriticalThreshold THEN 'CRITICAL'
    WHEN PASS_RATE < @WarningThreshold THEN 'WARNING'
    ELSE 'OK'
  END AS SEVERITY,
  CHECK_NAME,
  TABLE_NAME,
  CHECK_TYPE,
  PASS_RATE,
  FAILED_COUNT,
  STATUS,
  EXECUTION_TIME,
  'Action Required: Review data quality failure and investigate root cause' AS ACTION
FROM CONTROL.DATA_QUALITY_RESULTS
WHERE STATUS = 'FAIL'
  AND EXECUTION_TIME >= DATEADD(HOUR, -24, GETDATE())
ORDER BY PASS_RATE ASC, EXECUTION_TIME DESC;`,
      },
      trendsAndHistory: {
        name: "Data Quality Trends & Historical Analysis",
        description: "Track quality metrics over time",
        sql: `-- Data Quality Trends: 30-Day Historical Analysis
-- Purpose: Identify quality trends and recurring issues

DECLARE @Last30Days DATETIME2 = DATEADD(DAY, -30, GETDATE());
DECLARE @Last7Days DATETIME2 = DATEADD(DAY, -7, GETDATE());

SELECT 
  CHECK_NAME,
  TABLE_NAME,
  CHECK_TYPE,
  COUNT(*) AS TOTAL_CHECKS,
  AVG(PASS_RATE) AS AVG_PASS_RATE,
  MIN(PASS_RATE) AS MIN_PASS_RATE,
  MAX(PASS_RATE) AS MAX_PASS_RATE,
  STDEV(PASS_RATE) AS PASS_RATE_VOLATILITY,
  SUM(CASE WHEN STATUS = 'FAIL' THEN 1 ELSE 0 END) AS FAIL_COUNT,
  CAST(SUM(CASE WHEN STATUS = 'FAIL' THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)) AS FAIL_RATE,
  CASE 
    WHEN CAST(SUM(CASE WHEN STATUS = 'FAIL' THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS DECIMAL(5,2)) > 20 THEN 'INVESTIGATE'
    ELSE 'NORMAL'
  END AS RECOMMENDATION
FROM CONTROL.DATA_QUALITY_RESULTS
WHERE EXECUTION_TIME >= @Last30Days
GROUP BY CHECK_NAME, TABLE_NAME, CHECK_TYPE
ORDER BY FAIL_RATE DESC, AVG_PASS_RATE ASC;`,
      },
    },
  },
};

export const DataQualityFramework = {
  controlTables: {
    dataQualityResults: {
      name: "CONTROL.DATA_QUALITY_RESULTS",
      description: "Central repository for all DQ check results",
      ddl: `CREATE TABLE CONTROL.DATA_QUALITY_RESULTS (
  DQ_RESULT_ID BIGINT IDENTITY(1,1) PRIMARY KEY,
  CHECK_NAME NVARCHAR(256) NOT NULL,
  TABLE_NAME NVARCHAR(256) NOT NULL,
  CHECK_TYPE NVARCHAR(256) NOT NULL,
  PASSED_COUNT INT NOT NULL,
  FAILED_COUNT INT NOT NULL,
  TOTAL_COUNT INT NOT NULL,
  PASS_RATE DECIMAL(5,2) NOT NULL,
  STATUS NVARCHAR(20) NOT NULL,
  EXECUTION_TIME DATETIME2 NOT NULL DEFAULT GETDATE(),
  CREATED_DATE DATETIME2 NOT NULL DEFAULT GETDATE(),
  UNIQUE (CHECK_NAME, TABLE_NAME, CHECK_TYPE, CAST(EXECUTION_TIME AS DATE))
);
CREATE INDEX IX_DQ_Results_Table_Date ON CONTROL.DATA_QUALITY_RESULTS(TABLE_NAME, EXECUTION_TIME);
CREATE INDEX IX_DQ_Results_Status ON CONTROL.DATA_QUALITY_RESULTS(STATUS, EXECUTION_TIME);`,
    },
    dataQualityExceptions: {
      name: "CONTROL.DATA_QUALITY_EXCEPTIONS",
      description: "Track known exceptions and tolerances",
      ddl: `CREATE TABLE CONTROL.DATA_QUALITY_EXCEPTIONS (
  EXCEPTION_ID BIGINT IDENTITY(1,1) PRIMARY KEY,
  CHECK_NAME NVARCHAR(256) NOT NULL,
  TABLE_NAME NVARCHAR(256) NOT NULL,
  CHECK_TYPE NVARCHAR(256) NOT NULL,
  THRESHOLD DECIMAL(5,2) NOT NULL,
  REASON NVARCHAR(MAX),
  APPROVED_BY NVARCHAR(256),
  APPROVAL_DATE DATETIME2,
  EXPIRY_DATE DATETIME2,
  IS_ACTIVE BIT DEFAULT 1,
  CREATED_DATE DATETIME2 DEFAULT GETDATE()
);`,
    },
  },
  bestPractices: [
    "Run DQ checks after every data load into Bronze layer",
    "Implement automated alerting for critical quality failures",
    "Review DQ trends weekly to identify recurring issues",
    "Maintain exception list with documented approvals",
    "Track DQ metrics as part of data governance",
    "Implement reconciliation checks between layers (Bronze→Silver→Gold)",
    "Use statistical methods (mean, std dev) for outlier detection",
    "Document all business rules that inform DQ validations",
    "Implement data lineage tracking for root cause analysis",
    "Publish DQ metrics to stakeholders on agreed cadence",
  ],
};

export default DataQualityScripts;
